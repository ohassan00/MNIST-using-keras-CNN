{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load MNIST Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
      "11165696/11490434 [============================>.] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flatten 28*28 images to a 784 vector for each image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_pixels = X_train.shape[1] * X_train.shape[2]\n",
    "X_train = X_train.reshape(X_train.shape[0], -1).astype('float32')\n",
    "X_test = X_test.reshape(X_test.shape[0], -1).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. Training examples:  60000\n",
      "X_train shape:  (60000, 784)\n",
      "X_test shape:  (10000, 784)\n"
     ]
    }
   ],
   "source": [
    "print('No. Training examples: ', X_train.shape[0])\n",
    "print('X_train shape: ', X_train.shape)\n",
    "print('X_test shape: ' , X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode outputs to one-hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train = keras.utils.to_categorical(y_train, num_classes=10)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize inputs from 0-255 to 0-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train /= 255\n",
    "X_test /= 255 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shallow NN with 100-units hidden layer and softmax output layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hidden layer\n",
    "model.add(Dense(100, activation='relu', \n",
    "                input_dim=num_pixels, \n",
    "                kernel_initializer='VarianceScaling', \n",
    "                kernel_regularizer=keras.regularizers.l2(0.01)))\n",
    "\n",
    "# output layer\n",
    "model.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure the learning process with choice of:\n",
    "- **Optimizer**\n",
    "- **Loss function**\n",
    "- **List of Metrics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='Adam',\n",
    "             loss='categorical_crossentropy',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "0s - loss: 0.1941 - acc: 0.9675\n",
      "Epoch 2/60\n",
      "0s - loss: 0.1934 - acc: 0.9671\n",
      "Epoch 3/60\n",
      "0s - loss: 0.1881 - acc: 0.9686\n",
      "Epoch 4/60\n",
      "0s - loss: 0.1878 - acc: 0.9681\n",
      "Epoch 5/60\n",
      "0s - loss: 0.1858 - acc: 0.9693\n",
      "Epoch 6/60\n",
      "0s - loss: 0.1847 - acc: 0.9685\n",
      "Epoch 7/60\n",
      "0s - loss: 0.1837 - acc: 0.9691\n",
      "Epoch 8/60\n",
      "0s - loss: 0.1820 - acc: 0.9694\n",
      "Epoch 9/60\n",
      "0s - loss: 0.1788 - acc: 0.9698\n",
      "Epoch 10/60\n",
      "0s - loss: 0.1796 - acc: 0.9700\n",
      "Epoch 11/60\n",
      "0s - loss: 0.1803 - acc: 0.9696\n",
      "Epoch 12/60\n",
      "0s - loss: 0.1779 - acc: 0.9702\n",
      "Epoch 13/60\n",
      "0s - loss: 0.1764 - acc: 0.9706\n",
      "Epoch 14/60\n",
      "0s - loss: 0.1758 - acc: 0.9706\n",
      "Epoch 15/60\n",
      "0s - loss: 0.1725 - acc: 0.9715\n",
      "Epoch 16/60\n",
      "0s - loss: 0.1726 - acc: 0.9710\n",
      "Epoch 17/60\n",
      "0s - loss: 0.1725 - acc: 0.9711\n",
      "Epoch 18/60\n",
      "0s - loss: 0.1716 - acc: 0.9712\n",
      "Epoch 19/60\n",
      "0s - loss: 0.1685 - acc: 0.9718\n",
      "Epoch 20/60\n",
      "0s - loss: 0.1691 - acc: 0.9718\n",
      "Epoch 21/60\n",
      "0s - loss: 0.1693 - acc: 0.9721\n",
      "Epoch 22/60\n",
      "0s - loss: 0.1687 - acc: 0.9712\n",
      "Epoch 23/60\n",
      "0s - loss: 0.1649 - acc: 0.9720\n",
      "Epoch 24/60\n",
      "0s - loss: 0.1675 - acc: 0.9716\n",
      "Epoch 25/60\n",
      "0s - loss: 0.1626 - acc: 0.9732\n",
      "Epoch 26/60\n",
      "0s - loss: 0.1656 - acc: 0.9726\n",
      "Epoch 27/60\n",
      "0s - loss: 0.1639 - acc: 0.9729\n",
      "Epoch 28/60\n",
      "0s - loss: 0.1651 - acc: 0.9722\n",
      "Epoch 29/60\n",
      "0s - loss: 0.1646 - acc: 0.9721\n",
      "Epoch 30/60\n",
      "0s - loss: 0.1607 - acc: 0.9731\n",
      "Epoch 31/60\n",
      "0s - loss: 0.1587 - acc: 0.9746\n",
      "Epoch 32/60\n",
      "0s - loss: 0.1594 - acc: 0.9736\n",
      "Epoch 33/60\n",
      "0s - loss: 0.1595 - acc: 0.9734\n",
      "Epoch 34/60\n",
      "0s - loss: 0.1592 - acc: 0.9739\n",
      "Epoch 35/60\n",
      "0s - loss: 0.1607 - acc: 0.9724\n",
      "Epoch 36/60\n",
      "0s - loss: 0.1555 - acc: 0.9743\n",
      "Epoch 37/60\n",
      "0s - loss: 0.1583 - acc: 0.9731\n",
      "Epoch 38/60\n",
      "0s - loss: 0.1562 - acc: 0.9744\n",
      "Epoch 39/60\n",
      "0s - loss: 0.1547 - acc: 0.9746\n",
      "Epoch 40/60\n",
      "0s - loss: 0.1564 - acc: 0.9738\n",
      "Epoch 41/60\n",
      "0s - loss: 0.1547 - acc: 0.9744\n",
      "Epoch 42/60\n",
      "0s - loss: 0.1549 - acc: 0.9740\n",
      "Epoch 43/60\n",
      "0s - loss: 0.1536 - acc: 0.9748\n",
      "Epoch 44/60\n",
      "0s - loss: 0.1528 - acc: 0.9743\n",
      "Epoch 45/60\n",
      "0s - loss: 0.1522 - acc: 0.9754\n",
      "Epoch 46/60\n",
      "0s - loss: 0.1540 - acc: 0.9740\n",
      "Epoch 47/60\n",
      "0s - loss: 0.1540 - acc: 0.9738\n",
      "Epoch 48/60\n",
      "0s - loss: 0.1542 - acc: 0.9739\n",
      "Epoch 49/60\n",
      "0s - loss: 0.1538 - acc: 0.9735\n",
      "Epoch 50/60\n",
      "0s - loss: 0.1510 - acc: 0.9748\n",
      "Epoch 51/60\n",
      "0s - loss: 0.1486 - acc: 0.9754\n",
      "Epoch 52/60\n",
      "0s - loss: 0.1474 - acc: 0.9757\n",
      "Epoch 53/60\n",
      "0s - loss: 0.1496 - acc: 0.9751\n",
      "Epoch 54/60\n",
      "0s - loss: 0.1550 - acc: 0.9742\n",
      "Epoch 55/60\n",
      "0s - loss: 0.1535 - acc: 0.9742\n",
      "Epoch 56/60\n",
      "0s - loss: 0.1499 - acc: 0.9754\n",
      "Epoch 57/60\n",
      "0s - loss: 0.1481 - acc: 0.9754\n",
      "Epoch 58/60\n",
      "0s - loss: 0.1489 - acc: 0.9755\n",
      "Epoch 59/60\n",
      "0s - loss: 0.1493 - acc: 0.9753\n",
      "Epoch 60/60\n",
      "0s - loss: 0.1498 - acc: 0.9753\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fc1e5c544a8>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, \n",
    "         epochs=60,\n",
    "         batch_size=256, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 6912/10000 [===================>..........] - ETA: 0sTest set accuracy: 97.53%\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, y_test, batch_size=256)\n",
    "print(\"Test set accuracy: %.2f%%\" % (score[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying the same network replacing L2 Regularization with Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_2 = Sequential()\n",
    "\n",
    "# hidden layer\n",
    "model_2.add(Dense(100, activation='relu', \n",
    "                input_dim=num_pixels, \n",
    "                kernel_initializer='VarianceScaling',))\n",
    "model_2.add(Dropout(0.5))\n",
    "\n",
    "# output layer\n",
    "model_2.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model_2.compile(optimizer='Adam',\n",
    "             loss='categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model_2.fit(X_train, y_train, \n",
    "         epochs=60,\n",
    "         batch_size=256, verbose=2)\n",
    "\n",
    "scores = model_2.evaluate(X_test, y_test, batch_size=256)\n",
    "print(\"Test set accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.5 (Experimental) with Spark 2.1",
   "language": "python",
   "name": "python3-spark21"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
